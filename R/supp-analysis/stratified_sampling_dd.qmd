---
title: "Effect of length-stratified sampling for estimation of density dependence"
format: 
  html:
    embed-resources: true
editor: source
execute: 
  echo: true
  eval: true
  cache: false
---

```{r}
#| message: false
#| warning: false
library(tidyr)
library(dplyr)
library(ggplot2)
library(readr)
library(janitor)
library(sdmTMB)
library(tweedie)

theme_set(theme_light())

home <- here::here()
```

Read in trawl data to get reasonable values for total counts per haul and the length distribution

```{r}
#| message: false
#| warning: false

trawl_surveys_cod <- read_delim(paste0(home, "/data/stomach-data/BITS/trawl/Trawl Surveys Zincl (L) COD.csv"), delim = ";")
trawl_surveys_fle <- read_delim(paste0(home, "/data/stomach-data/BITS/trawl/Trawl Surveys Zincl (L) FLE.csv"), delim = ";")

# Combine for the two species, filter and clean!
trawl_data <- rbind(trawl_surveys_cod, trawl_surveys_fle) |>
  clean_names() |>
  mutate(swept_area = as.numeric(gsub(",", "\\.", swept_area)),
         kg_hour = as.numeric(gsub(",", "\\.", kg_hour)),
         dist = as.numeric(gsub(",", "\\.", dist))) |> 
  as.data.frame()

sort(unique(trawl_data$lat)) |> head(20)

# For these coordinates, we can use the function Fede provided:
format.position <- function(x){
  sign.x <- sign(x)
  x <- abs(x)
  x <- ifelse(nchar(x)==3, paste("0",x,sep=""), x)
  x <- ifelse(nchar(x)==2, paste("00",x,sep=""), x)
  x <- ifelse(nchar(x)==1, paste("000",x,sep=""), x)
  dec.x <- as.numeric(paste(substring(x,1,2)))+as.numeric(paste(substring(x,3,4)))/60
  dec.x <- sign.x*dec.x
}

# Apply function
trawl_data$lat <- format.position(trawl_data$lat)
trawl_data$lon <- format.position(trawl_data$long)

trawl_data <- sdmTMB::add_utm_columns(trawl_data, ll_names = c("lon", "lat"))

# What is the total size distribution 
ggplot(trawl_data, aes(lengthcl/10)) +
  geom_histogram() + 
  facet_wrap(~species, ncol = 1)

trawl_data |> 
  mutate(haul_id = paste(date, haul, station_name, lat, long, sep = "_")) |> 
  mutate(tot_by_haul = tot_no_hour * (duration / 60)) |>
  ggplot(aes(tot_by_haul)) +
  geom_histogram()

summary(trawl_data$tot_no_hour * (trawl_data$duration / 60))

# Assume a normal distribution of the trawl catches... A typical haul has 25 fish (some 0 though but obviously we don't sample any stomachs here!)

# So, this could be a length-frequency distribution in a typical haul
hist(rnorm(mean = 30, sd = 3, n = 30))
summary(rnorm(mean = 30, sd = 3, n = 30))
```

Example simulating data

```{r}
#| include: false
# set.seed(123)
# 
# N <- 500
# 
# predictor_dat <- data.frame(
#   X = runif(N), Y = runif(N)
# )
# 
# mesh <- make_mesh(predictor_dat, xy_cols = c("X", "Y"), cutoff = 0.01)
# 
# plot(mesh)
# 
# # Ok, this code generates 1 obs per "haul". So if I repeat this x times, for each haul i should get a distribution of fishes. I do this 30 times then to get 30 fishes per haul, and hope the size distribution looks alright (per haul). But then there's no spatial structure in the total by haul... 
# 
# pd <- sdmTMB_simulate(
#   formula = ~1,
#   data = predictor_dat,
#   mesh = mesh,
#   family = nbinom1(),
#   range = 0.7,
#   phi = 0.02,
#   sigma_O = 0.6,
#   B = c(5)
#   )
# 
# pd |> 
#   ggplot(aes(X, Y, colour = observed)) +
#   geom_point(size = 5) +
#   scale_color_viridis_c()
# 
# summary(pd$observed)
# 
# # Add to the predictor data
# predictor_dat <- predictor_dat |> 
#   mutate(tot_count = pd$observed,
#          tot_count = ifelse(tot_count == 0, 1, tot_count))
# 
# summary(predictor_dat$tot_count)
# hist(predictor_dat$tot_count)
# 
# # Now I want to "uncount" the data frame... and randomly assign a length to each row, which now represents an individual
# d <- predictor_dat |> 
#   uncount(tot_count, .remove = FALSE) |> 
#   mutate(length = round(rnorm(n(), 25, 3)),
#          haul_id = paste(X, Y, sep = "_"))
# 
# # Do we still have a spatial pattern in the total count by haul?
# d |> 
#   summarise(sum = n(), .by = c(X, Y)) |> 
#   ggplot(aes(X, Y, colour = sum)) +
#   geom_point(size = 5) +
#   scale_color_viridis_c()
# 
# # What is the size distribution by haul?
# d |> 
#   filter(haul_id %in% sample(haul_id, 20)) |> 
#   ggplot(aes(length, colour = haul_id)) +
#   geom_density() + 
#   guides(color = "none")
# 
# # What is the distribution of catches?
# d |>
#   distinct(haul_id, .keep_all = TRUE) |>
#   ggplot(aes(tot_count)) +
#   geom_histogram()
# 
# # Simulate Tweedie observations (stomach contents) (parameters roughly what we see in Saduria)
# # The slope is the effect of total density, so we need to sum that by haul. The slope 0.75 is on the scaled density, so scale it now
# 
# d <- d |> 
#   mutate(tot_count_sc = (tot_count - mean(tot_count)) / sd(tot_count))
# 
# hist(d$tot_count_sc)
# 
# # Let the mean of the Tweedie change with density
# # intercept <- 0.001
# # slope <- -0.0003
# # 
# # mu <- intercept + slope*d$tot_count_sc
# 
# # True parameters for simulation
# intercept <- log(0.0005)  # log scale
# slope <- -0.75    # effect of covariate
# 
# # Calculate mean on log scale
# mu <- exp(intercept + slope * d$tot_count_sc)
# 
# hist(mu)
# 
# p <- 1.8        # power parameter for Tweedie
# phi <- 4        # dispersion parameter
# 
# y <- rtweedie(
#   n = nrow(d), 
#   mu = mu,    # mean depends on covariate
#   phi = phi,  # dispersion parameter
#   power = p   # power parameter
# )
# 
# hist(y)
# summary(y)
# 
# d$y <- y
# 
# ggplot(d, aes(tot_count_sc, y)) + 
#   geom_jitter()
# 
# summary(d$y)
# 
# m <- sdmTMB(y ~ tot_count_sc,
#             data = d, 
#             spatial = "off",
#             family = tweedie())
# 
# sanity(m)
# print(m)
# tidy(m)
```

General N trawl data sets

```{r}

df_list <- list()

N <- 300

for(i in 1:100){
  
  predictor_dat <- data.frame(
    X = runif(N), Y = runif(N)
    )

  mesh <- make_mesh(predictor_dat, xy_cols = c("X", "Y"), cutoff = 0.01)

  pd <- sdmTMB_simulate(
    formula = ~1,
    data = predictor_dat,
    mesh = mesh,
    family = nbinom1(),
    range = 0.7,
    phi = 0.02,
    sigma_O = 0.6,
    B = c(5)
    )
  
  # Add to the predictor data
  predictor_dat <- predictor_dat |> 
    mutate(tot_count = pd$observed,
           tot_count = ifelse(tot_count == 0, 1, tot_count))
  
  # Now I want to "uncount" the data frame... and randomly assign a length to each row, which now represents an individual
  d <- predictor_dat |> 
    uncount(tot_count, .remove = FALSE) |> 
    mutate(length = round(rnorm(n(), 25, 3)),
           haul_id = paste(X, Y, sep = "_"))

  d <- d |> 
    mutate(tot_count_sc = (tot_count - mean(tot_count)) / sd(tot_count))

  
  # tweedie parameters
  intercept <- log(0.0005)  # log scale
  slope <- -0.75    # effect of covariate
  p <- 1.8        # power parameter for Tweedie
  phi <- 2        # dispersion parameter

  # Calculate mean on log scale
  mu <- exp(intercept + slope * d$tot_count_sc)

  y <- rtweedie(
    n = nrow(d), 
    mu = mu,    # mean depends on covariate
    phi = phi,  # dispersion parameter
    power = p   # power parameter
    )

  d$y <- y

  df_list[[i]] <- d |> mutate(replicate = i)
  
}

df <- bind_rows(df_list)
```

Ok, now we have a data frame where:

- 1 row is one individual
- The total catch by haul is between approx 1-80 individuals
- Each individual is assigned a length
- Each individual gets a relative prey weight from a tweedie distribution that depends linearly on the total catch in the haul

Now we fit models to 1) the full data 2) length-stratified random sampling by haul 3) #2 but use total catch as a weight

```{r}

coefs <- list()

for(i in unique(df$replicate)){
  
  dd <- filter(df, replicate == i)
  
  mesh <- make_mesh(dd, xy_cols = c("X", "Y"), cutoff = 0.05)

  m1 <- sdmTMB(y ~ tot_count_sc,
               data = dd, 
               mesh = mesh,
               spatial = "off",
               family = tweedie(),
               )

  m1 <- run_extra_optimization(m1)
  
  # Now do length-stratified sampling (1 from each length class for each haul, irrespective of total haul catch)
  dd2 <- d |> 
    mutate(pred_id = 1:n()) |> 
    group_by(haul_id, length) |> 
    slice_sample(n = 1) |>
    ungroup()
  
  mesh2 <- make_mesh(dd2, xy_cols = c("X", "Y"), cutoff = 0.01)
  
  m2 <- sdmTMB(y ~ tot_count_sc,
               data = dd2, 
               mesh = mesh2,
               spatial = "off",
               family = tweedie(),
               )

  m2 <- run_extra_optimization(m2)
  
  # Now do length-stratified sampling (1 from each length class for each haul, irrespective of total haul catch), but use weights
  weights <- dd2$tot_count / mean(dd2$tot_count)
  
  m3 <- sdmTMB(y ~ tot_count_sc,
               data = dd2, 
               weights = weights,
               mesh = mesh2,
               spatial = "off",
               family = tweedie(),
               )

  m3 <- run_extra_optimization(m3)
  
  coefs[[i]] <- bind_rows(tidy(m1) |> mutate(model = "m1"),
                          tidy(m2) |> mutate(model = "m2"),
                          tidy(m3) |> mutate(model = "m3"))
  
}

cd <- bind_rows(coefs)

cd |> 
  filter(term == "tot_count_sc") |> 
  ggplot(aes(estimate, model)) + 
  geom_jitter(width = 0, height = 0.2, alpha = 0.3) +
  geom_violin(fill = NA, color = "steelblue", linewidth = 0.6) + 
  geom_boxplot(fill = NA, width = 0.1, linewidth = 1, color = "steelblue") +
  geom_vline(xintercept = slope)
```



